---
title: "Malurus Pop Gen"
author: "Elroy Au"
date: "05/09/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

### ================================== ###
### Samples Distribution Map           ###
### ================================== ###

```Generate a map of the distribution of M. assimilis tissue samples across Australia coded by collection date```

```{r}

# load libraries
library(oz)
library(readxl)

# load dataset
samples <- read_excel("Samples-Geo-Date.xlsx")
```

```{r}

# set the latitudes and longitudes of points  
lat1 <- samples$`Latitude-1`        
lat2 <- samples$`Latitude-2`       
lat3 <- samples$`Latitude-3`        
lat4 <- samples$`Latitude-4`        
lat5 <- samples$`Latitude-5`        
lat6 <- samples$`Latitude-6`       
lat7 <- samples$`Latitude-7`
long1 <- samples$`Longitude-1`
long2 <- samples$`Longitude-2`
long3 <- samples$`Longitude-3`
long4 <- samples$`Longitude-4`
long5 <- samples$`Longitude-5`
long6 <- samples$`Longitude-6`
long7 <- samples$`Longitude-7`
```

```{r}

# plot Australia 

oz()

# plot points 

points(long1,lat1, col = "#85C1E9", bg = "#85C1E9", pch = 24)   
points(long2,lat2, col = "#5DADE2", bg = "#5DADE2", pch = 24)
points(long3,lat3, col = "#3498DB", bg = "#3498DB", pch = 24)
points(long4,lat4, col = "#2E86C1", bg = "#2E86C1", pch = 24)
points(long5,lat5, col = "#2874A6", bg = "#2874A6", pch = 24)
points(long6,lat6, col = "#21618C", bg = "#21618C", pch = 24)
points(long7,lat7, col = "#1B4F72", bg = "#1B4F72", pch = 24)
```

### ================================== ###
### SNP Parameters                     ###
### ================================== ###

```Plotting parameters calculated for SNP filtering including: Coverage Depth,
Individual Missingness, Average Site Depth and Site Missingness```

### Coverage Depth 

```{r}

# load libraries
library(ggplot2)
library(readxl)

# load dataset 
# this is an excel file containing the coverage of each individual sample as 
# estimated using SamTools 

coverage <- read_excel("coverage.xlsx")
```

```{r}

# plot a histogram of the distribution of sample coverage using ggplot2

ggplot (coverage, aes(coverage$`Coverage Depth`)) + geom_histogram(breaks=seq(0,8, by =1), col="grey1", aes(fill=..count..)) + scale_fill_gradient("Count", high = "paleturquoise4", low = "paleturquoise1") + labs(x="Coverage Depth", y = "Frequency") + theme_bw()
```

### Average Site Depth 

```{r}

# load libraries
library(ggplot2)
library(readxl)

# load dataset 
# this is an excel file containing the average depth of 100,000 random sites
# trimmed of sites with average depth >8 as these sites drag the histogram out
# such that the resolution is unreadable 
meansitedepth <- read_excel("mean-site-depth-trimmed-2.xlsx")
```

```{r}

# set the variable sitedepth 
sitedepth <- meansitedepth$`Mean Site Depth`

# create a histogram 
hist(sitedepth, breaks=100, main = "Average Site Depth",    
     xlab = "Average Site Depth") 

# calculate the average depth
mean <- mean(sitedepth) 

# calculate the standard deviation
SD <- sd(sitedepth)  

# calculate 3 standard deviations
sdevs <- SD * 3  

# set the cutoff for average site depth as anything above this are usually 
# sequencing artefacts or paralogs 
cutoff <- sdevs + mean

# add lines representing the average site depth and cutoff site depth to the 
# histogram
abline(v = mean, col = "red", lwd = 2)                      
abline(v = cutoff, col = "blue", lwd = 2)
```

### Individual Missingness             

```{r}

# load libraries
library(ggplot2)    
library(readxl)

# load dataset
# this is an excel file containing the individual missingness values for all
# samples across all 25 chromosomes 
missingness <- read_excel("missingness.xlsx")
```

```{r}

# plot missingness
ggplot (missingness, aes(missingness)) + geom_histogram(breaks=seq(0,0.8, by =0.1), col="grey1", aes(fill=..count..)) + scale_fill_gradient("Count", high = "red4", low = "palevioletred2") + labs(x="Individual Missingness", y = "Frequency") + theme_bw()
```

### Site Missingness 

```{r}

# load libraries 
library(ggplot2)    
library(readxl)

# load dataset
# this is an excel file containing the missingness of 100,000 sites across
# all 25 chromosomes
sitemissingness <- read_excel("site-missingness.xlsx")
```

```{r}

# plot site missingness 

ggplot (sitemissingness, aes(sitemissingness$`site-missingness`)) + geom_histogram(breaks=seq(0,1, by =0.1), col="grey1", aes(fill=..count..)) + scale_fill_gradient("Count", high = "goldenrod2", low = "lightgoldenrod2") + labs(x="Site Missingness", y = "Frequency") + theme_bw()
```

### ================================== ###
### Data Analysis                      ###
### ================================== ###

### ================================== ###
### PCA                                ###
### ================================== ###

```{r}

# load libraries

library(ggplot2)
library(readxl) 
library(RcppCNPy)     # for reading .npy (NUMPY) files
library(sf) 

# load datasets
# PCA.cov.npy is the covariance matrix without outlier individuals filtered, n=133
# PCA.filtered.cov.npy is the covariance matrix with outlier individuals filtered, # n = 119
# PCA.climate.cov.npy is the covariance matrix with individuals from PCA.filtered.cov.npy who are missing climate data removed
covmatrix <- npyLoad("PCA.cov.npy")  
covmatrixfiltered <- npyLoad("PCA.filtered.cov.npy")
climcovmatrix <- npyLoad("PCA.climate.cov.npy")
```

```{r}
# calculate eigenvalues
Eigenvalues <- eigen(covmatrixfiltered)$values         
# calculate eigenvectors
Eigenvectors <- eigen(covmatrixfiltered)$vectors  
# calculate the principal components using a matrix multiplication 
PC <- as.matrix(covmatrixfiltered) %*% Eigenvectors

# calculate the proportions of the variation explained by the various components
print(round(Eigenvalues/sum(Eigenvalues) * 100, digits = 2))
round(cumsum(Eigenvalues)/sum(Eigenvalues) * 100, digits = 2)
```

```{r}

# load the new data
PCA <- read_excel("PCA-metadata.xlsx")

# plot principal components with the collection date and geographic
# location (state) metadata 
ggplot(PCA, aes(x=PC1, y=PC2)) + geom_point(aes(shape = Period, color = STATE), position = "jitter", size = 2.5) + scale_shape_manual(values = c(3, 4, 8, 15, 17, 18, 19, 25)) + theme_bw() 

# plot principal components with the collection date and indvidual 
# missingness metadata
ggplot (PCA, aes(x=PC1, y=PC2)) + geom_point(aes(shape = Period, color = MISSINGNESS), position = "jitter", size = 2.5) + scale_shape_manual(values = c(3, 4, 8, 15, 17, 18, 19, 25)) + scale_color_continuous(high = "black", low = "turquoise2") + theme_bw() 

# plot samples by latitude and longitude on a scale of principal 
# componentvalues

australia <- st_read("australia.shp")
a <- ggplot() + geom_sf(data = australia, color = "black", fill = "white")
a + geom_point(data=PCA, aes(x=LONGITUDE, y=LATITUDE, color = PC1), size = 2.5) + scale_color_gradient2()
```

```{r}

# create a biplot by hand
# load libraries
library(readxl)

# load dataset 
pca.metadata <- read_excel("Biplot Metadata.xlsx")

# set pch and colour groups (grouped by geography: NSW, NT, QLD, SA, VIC, WA, NA)
pch.group <- c(rep(0, times=10), rep(1, times=10), rep(2, times=10), rep(5, times=43), rep(3, times=1), rep(6, times=43), rep(4, times=2))

col.group <- c(rep("lightgreen", times=10), rep("violet", times=10), rep("gold", times=10), rep("red", times=43), rep("pink", times=1), rep("skyblue2", times=43), rep("grey", times=2))

# plot the individuals in principal component space grouped by their shape and colour for state of collection 
plot(x=pca.metadata$PC1, y=pca.metadata$PC2, xlab="PC1 (3.18%)", ylab="PC2 (1.23%)", pch=pch.group, col="black", bg=col.group, cex=2, las=1, asp=1)

# add horizontal and vertical axes at zero 
abline(v=0, lty=2, col="grey50")
abline(h=0, lty=2, col="grey50")


```

### ================================== ###
### Linear Regression                  ###
### ================================== ###

```{r}

# load libraries

library(ggplot2)   
library(readxl)     
library(tidyverse)  # for correlation matrix

# load the new data
PCA <- read_excel("PCA-metadata.xlsx")

# linear regression model of PC1 values and individual missingness 
regression <- lm(PC1~MISSINGNESS, data = PCA)

summary(regression) 

# calculate the Pearson's correlation coefficient 
cPC1 <- PCA$PC1
cMiss <- PCA$MISSINGNESS
cor.test(cMiss, cPC1, method=c("pearson")) 

# create a correlation matrix 
cor(PCA %>% select(PC1, PC2, Year, LATITUDE, LONGITUDE), use="pairwise.complete.obs")

# plot a linear regression 
ggplot(PCA, aes(y=PC1, x=MISSINGNESS)) + geom_point() + geom_smooth(method="lm") + theme_bw()
```

### ================================== ###
### NGSadmix - ADMIXTURE               ###
### ================================== ###

```{r}

# load libraries
library(RColorBrewer)

# load the data 

pop <- read.table("Admix-Pop-Data.txt", fill = TRUE, header = FALSE)

q2 <- read.table("admix.2.txt", fill = TRUE, header = FALSE)

q3 <- read.table("admix.3.txt", fill = TRUE, header = FALSE)

q4 <- read.table("admix.4.txt", fill = TRUE, header = FALSE)

q5 <- read.table("admix.5.txt", fill = TRUE, header = FALSE)

q6 <- read.table("admix.6.txt", fill = TRUE, header = FALSE)


# order according to population
ord <- order (pop[,2])

# plot admixture for k
barplot(t(q2)[,ord],col=2:10, space=0, border=NA, xlab="Individuals", ylab="AdmixtureProportions(K=2)") 

# plot admixture for k using color brewer scheme 
barplot(t(q3)[,ord],col=brewer.pal(n=3, name="RdBu"),   
        space=0, border=NA, xlab="Individuals",         
        ylab="Admixture Proportions (K=3)")

# add individual population labels 
text(tapply(1:nrow(pop), pop[ord,2], mean),-0.05, unique(pop[ord,2]),xpd=T)  

# add lines between each individual and population
abline(v=cumsum(sapply(unique(pop[ord,1]), function(x){sum(pop[ord,1]==x)})), col="white",lwd=0.5)

abline(v=cumsum(sapply(unique(pop[ord,2]), function(x){sum(pop[ord,2]==x)})), col=1,lwd=2) 
```

### ================================== ###
### ADMIXTURE SCATTER PLOTS            ###
### ================================== ###

```{r}

# load libraries

library(ggplot2)       
library(ggrepel)        
library(scatterpie)     
library(sf) 
library(readxl)

admixture <- read_excel("admix-metadata.xlsx")

# load shapefile of Australia

australia <- st_read("australia.shp")

# create a vector plot of Australia 
a <- ggplot() + geom_sf(data = australia, color = "black", fill = "white") 

# K = 2

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K2.1
K2 <- admixture$K2.2

admixdata2 <- data.frame(Lat,Long,K1,K2)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata2, cols = c("K1", "K2")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 3

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K3.1
K2 <- admixture$K3.2
K3 <- admixture$K3.3

admixdata3 <- data.frame(Lat,Long,K1,K2,K3)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata3, cols = c("K1", "K2", "K3")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 4

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K4.1
K2 <- admixture$K4.2
K3 <- admixture$K4.3
K4 <- admixture$K4.4

admixdata4 <- data.frame(Lat,Long,K1,K2,K3,K4)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata4, cols = c("K1", "K2", "K3", "K4")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 5

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K5.1
K2 <- admixture$K5.2
K3 <- admixture$K5.3
K4 <- admixture$K5.4
K5 <- admixture$K5.5

admixdata5 <- data.frame(Lat,Long,K1,K2,K3,K4,K5)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata5, cols = c("K1", "K2", "K3", "K4", "K5")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 6

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K1
K2 <- admixture$K2
K3 <- admixture$K3
K4 <- admixture$K4
K5 <- admixture$K5
K6 <- admixture$K6

admixdata6 <- data.frame(Lat,Long,K1,K2,K3,K4,K5,K6)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata6, cols = c("K1", "K2", "K3", "K4", "K5", "K6")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()
```

### =============================================== ###
### CALCULATING CLIMATE VARIABLES - RATE OF CHANGE  ###
### =============================================== ###

```First estimate slopes for change in each climate variable over time; separate file for each climate variable. yearJD - year jan-dec for winter variables. yearJJ - year july-june for summer variables. slopes based on 20 years of data prior to capture year. Removed year of capture as the amount of months each sample is exposed to in the year is variable (e.g. could be <1 if caught in January).```

```{r}
#### CHANGE IN MEAN TEMPERATURE ####

Change.Tmean <- read.csv("Tmean.ForChange.csv", header = T)
summary(Change.Tmean)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7"  
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137","ANWC138","ANWC139","ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147","ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157","ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66","ANWC67","ANWC68","ANWC69","ANWC71","ANWC72","ANWC73","ANWC75","ANWC77","ANWC78","ANWC79","ANWC80","ANWC81","ANWC84","ANWC85","ANWC88","ANWC90","ANWC92","ANWC94","SAM11","SAM12","SAM14","SAM15","SAM16","SAM17","SAM18","SAM19","SAM20","SAM21","SAM25","SAM26","SAM27","SAM28","SAM29", "SAM30","SAM31","SAM32","SAM33","SAM34","SAM35","SAM36","SAM37","SAM38","SAM39","SAM41", "SAM44","SAM45","SAM46","SAM8","WAM55","WAM56","WAM57","WAM58","WAM59","WAM60","WAM63","WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file
for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(Tmean ~ scale(YearJJ, scale=FALSE),  
                 data = subset(Change.Tmean, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially 
write.csv(Model.sample,"ChangeMeanTemp.csv") 
```

```{r}
#### CHANGE IN NO. DAYS OVER 35 ####

Change.Ndays35<- read.csv("NDays35.ForChange.csv", header = T)
summary(Change.Ndays35)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7"  
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137","ANWC138","ANWC139","ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147","ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157","ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66","ANWC67","ANWC68","ANWC69","ANWC71","ANWC72","ANWC73","ANWC75","ANWC77","ANWC78","ANWC79","ANWC80","ANWC81","ANWC84","ANWC85","ANWC88","ANWC90","ANWC92","ANWC94","SAM11","SAM12","SAM14","SAM15","SAM16","SAM17","SAM18","SAM19","SAM20","SAM21","SAM25","SAM26","SAM27","SAM28","SAM29", "SAM30","SAM31","SAM32","SAM33","SAM34","SAM35","SAM36","SAM37","SAM38","SAM39","SAM41", "SAM44","SAM45","SAM46","SAM8","WAM55","WAM56","WAM57","WAM58","WAM59","WAM60","WAM63","WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file
for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(NDays35 ~ scale(YearJJ, scale=FALSE),  
                 data = subset(Change.Ndays35, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially 
write.csv(Model.sample,"ChangeNdays35.csv")
```

```{r}
#### CHANGE IN NO. DAYS UNDER 5 ####

Change.NDays5 <- read.csv("NDays5.ForChange.csv", header = T)
summary(Change.Ndays5)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7", "WAM55", "ANWC84", "ANWC85", "ANWC88", "ANWC90","ANWC92"
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137", "ANWC138","ANWC139",	"ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147", "ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157", "ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66", "ANWC67", "ANWC68", "ANWC69", "ANWC71", "ANWC72", "ANWC73", "ANWC75", "ANWC77", "ANWC78","ANWC79", "ANWC80", "ANWC81", "ANWC94","SAM11", "SAM12", "SAM14", "SAM15", "SAM16", "SAM17", "SAM18", "SAM19", "SAM20", "SAM21","SAM25", "SAM26", "SAM27", "SAM28", "SAM29", "SAM30", "SAM31", "SAM32", "SAM33", "SAM34","SAM35", "SAM36", "SAM37", "SAM38", "SAM39", "SAM41", "SAM44", "SAM45", "SAM46", "SAM8", "WAM56", "WAM57", "WAM58", "WAM59", "WAM60", "WAM63", "WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file

for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(Ndays5 ~ scale(YearJD, scale=FALSE),  
                 data = subset(Change.NDays5, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially
write.csv(Model.sample,"ChangeNdays5.csv")
```

```{r}
#### CHANGE IN PRECIPITATION ####

Change.Rain <- read.csv("Rain.ForChange.csv", header = T)
summary(Change.Rain)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7"  
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137","ANWC138","ANWC139","ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147","ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157","ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66","ANWC67","ANWC68","ANWC69","ANWC71","ANWC72","ANWC73","ANWC75","ANWC77","ANWC78","ANWC79","ANWC80","ANWC81","ANWC84","ANWC85","ANWC88","ANWC90","ANWC92","ANWC94","SAM11","SAM12","SAM14","SAM15","SAM16","SAM17","SAM18","SAM19","SAM20","SAM21","SAM25","SAM26","SAM27","SAM28","SAM29", "SAM30","SAM31","SAM32","SAM33","SAM34","SAM35","SAM36","SAM37","SAM38","SAM39","SAM41", "SAM44","SAM45","SAM46","SAM8","WAM55","WAM56","WAM57","WAM58","WAM59","WAM60","WAM63","WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file
for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(RainSum ~ scale(YearJD, scale=FALSE),  
                 data = subset(Change.Rain, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially 
write.csv(Model.sample,"ChangeRain.csv")
```

```{r}
# Calculate the correlation matrix to test for correlations between the variables
# Import the data 
climate.corr <- read.csv("ElroyCorDataSummary.csv", header = T)

# Create the correlation matrix and write it into a new csv file
write.csv(cor(climate.corr[,2:17], use="pairwise.complete.obs"), "ElroyClimateCorMatrix.csv")
```

### ================================== ###
### CLIMATE VARIABLES PCA              ###
### ================================== ###

```{r}

#load libaries 
library(tidyverse)
library(readr)

# load dataset
# this dataset only contains the variables calculated for samples with values for all
# climate variables, i.e. there are no missing values (NA)
climate.var <- read.csv("ClimateVariablesPCA.csv")
NDays35_ForChange <- read_csv("NDays35.ForChange.csv")

# transpose data to look at amount of missing years 
spread(NDays35_ForChange, key=SAMPLE.ID, value=NDays35, fill=NA)

# compute the principal components. 
PCA <- prcomp(climate.var, scale. = T)
biplot(PCA, scale=0)
```

### ================================== ###
### DISTANCE MATRIX                    ###
### ================================== ###

```{r}

# how the distance matrix was calculated 
# load libraries
library(geosphere) # to create the distance matrix

longitude <- inbreedtestdata$LONGITUDE
latitude <- inbreedtestdata$LATITUDE
coord <- data.frame(longitude,latitude)
coordmatrix <- as.matrix(coord)
# calculate distance in metres using shortest distance between 
# 2 points method in geosphere package
distance <- distm(coordmatrix, fun=distGeo)
```

### ================================== ###
### MIXED MODELS                       ###
### ================================== ###

```{r}

# Load libraries 
library(readxl) 
library(ecodist) # mrm mixed models using distance matrices as co-variates and response
library(vegan) # adonis mixed models using distance matrices as response
library('MuMIn')
library(nlme) # linear modelling
library(lme4) # linear modelling
library(reshape2)

# Load datasets

climate.var <- read_excel("ClimVarMod.xlsx") # spatial analysis 

# text file containing the variance-covariance genetic matrix
# genetic matrix calculated using PCangsd 
genmatrix <- read.table("covariance-matrix.txt")
G <- as.matrix(genmatrix)

# text file containing the distance matrix 
distancem <- read.table("distance-matrix.txt")
D <- as.matrix(distancem)

# spatial inbreeding model

MRM(dist(INBREEDING) ~ as.dist(D) + as.dist(G) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=climate.var, nperm=500)

MRM(dist(INBREEDING) ~ as.dist(D) + as.dist(G) + dist(ScaledNdays35ten) + dist(ScaledNdays5ten) + dist(ScaledRainten) + dist(Year), data=climate.var, nperm=500)

# spatial genetics model

MRM(as.dist(G) ~ as.dist(D) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=climate.var, nperm=500)

# temporal inbreeding model 

M1.lmer<-lmer (INBREEDING ~ scale(NDays35.5YrMean, scale=TRUE) * scale(ChangeMeanTemp, scale=TRUE) + scale(Ndays5.5YrMean, scale=TRUE) * scale(ChangeMeanTemp, scale=TRUE) + scale(TotalRain.5YrSum, scale=TRUE) * scale(ChangeRain, scale=TRUE) + (1|YearCat) + (1|IBRA_REG_CODE_7), data = ElroyData, REML=F)

# temporal genetics model -- IS THIS OK?

adonis2(G ~ ScaledChangeMeanTemp * ScaledNdays35five + ScaledChangeMeanTemp * ScaledNdays5five + ScaledRainfive * ScaledChangeRain + Year + IBRA, data = climate.var)
```
